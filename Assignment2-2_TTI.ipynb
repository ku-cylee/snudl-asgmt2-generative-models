{"cells":[{"cell_type":"markdown","metadata":{"id":"7iKsvycwfG1S"},"source":["# M2177.003100 Deep Learning Assignment #2 <br> Part 2: Text-to-Image Synthesis"]},{"cell_type":"markdown","metadata":{"id":"z75r1oWmfG1V"},"source":["Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."]},{"cell_type":"markdown","metadata":{"id":"ii4cQtoufG1W"},"source":["**For understanding of this work, please carefully look at given PDF file.**\n","\n","**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."]},{"cell_type":"markdown","metadata":{"id":"gd-vX3cavOCt"},"source":["## 0. What is the Stable Diffusion?\n","\n","Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/) and [LAION](https://laion.ai/). It's trained on 512x512 images from a subset of the [LAION-5B](https://laion.ai/blog/laion-5b/) database. This model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM.\n","See the [model card](https://huggingface.co/CompVis/stable-diffusion) for more information.\n","\n","Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"QYOlvQ1nQL7c"},"source":["## 1. Setup\n","\n","First, please make sure you are using a GPU runtime to run this notebook, so inference is much faster."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHkHsdtnry57"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"paJt_cx5QgVz"},"source":["Next, you should install necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIrgth7sqFML"},"outputs":[],"source":["!pip install --quiet --upgrade diffusers transformers scipy mediapy accelerate ftfy spacy"]},{"cell_type":"markdown","metadata":{"id":"3NnPOMAqAABv"},"source":["## 2. Load the model (Stable Diffusion Pipeline)\n","\n","`StableDiffusionPipeline` is an end-to-end inference pipeline that you can use to generate images from text with just a few lines of code.\n","\n","First, we load the pre-trained weights of all components of the model.\n","\n","In addition to the model id [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4), we're also passing a specific `revision` and `torch_dtype` to the `from_pretrained` method.\n","Make sure you have succesfully login so that it can be verified that you have indeed accepted the model's license.\n","\n","We're loading the weights from the half-precision branch [`fp16`](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/fp16) and also tell `diffusers` to expect the weights in float16 precision by passing `torch_dtype=torch.float16`.\n","\n","If you want to ensure the highest possible precision, please make sure to remove `revision=\"fp16\"` and `torch_dtype=torch.float16` at the cost of a higher memory usage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSKWBKFPArKS","collapsed":true},"outputs":[],"source":["import torch\n","from diffusers import StableDiffusionPipeline\n","from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler, EulerDiscreteScheduler\n","\n","device = \"cuda\"\n","model_id = \"CompVis/stable-diffusion-v1-4\"\n","IMAGE_SIZE = 512\n","\n","scheduler = PNDMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    model_id,\n","    scheduler=scheduler,\n","    torch_dtype=torch.float16,\n","    revision=\"fp16\",\n","    )\n","pipe = pipe.to(device)"]},{"cell_type":"markdown","metadata":{"id":"8MgNzTxwbASv"},"source":["## 3. Generate the image from the text\n","\n","Below cell is an example to generate the images from the text 'a photo of nike air jordan shoes' with hyperparameters which are set by using default values in the paper.\n","\n","There are four hyperparameters you can change to generate the high quality images from the text\n","* `GUIDANCE_SCALE` : It is a way to increase the adherence to the conditional signal which in this case is text as well as overall sample quality. In simple terms, this hyperparameter forces the generation to better match with the prompt. This can also control the trade-off between the quality and diversity.\n","Numbers like `7` or `8.5` give good results, if you use a very large number the images might look good, but will be less diverse.\n","\n","* `NUM_DENOISING_STEPS` : It means how many denoising steps you excute to generate images from the pure Gaussian noise. In general, results are better the more steps you use while more steps make the longer generation process. Stable Diffusion, being one of the latest models, works great with a relatively small number of steps, so we recommend to use the default of `50`. If you want faster results you can use a smaller number. <font color=red>**You should use value smaller than 1000.**</font>\n","\n","* `SEED` : For the deterministic output, pass a random seed to the pipe line. Every time you use the same seed, you'll have the same image result."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LA9myHTxbDhm"},"outputs":[],"source":["NUM_IMAGES = 4\n","\n","prompt = \"a photo of nike air jordan shoes\"\n","GUIDANCE_SCALE = 7.5\n","NUM_DENOISING_STEPS = 50\n","SEED = 1234\n","\n","\n","images = pipe(\n","    prompt,\n","    num_images_per_prompt=NUM_IMAGES,\n","    guidance_scale=GUIDANCE_SCALE,\n","    num_inference_steps=NUM_DENOISING_STEPS,\n","    height=IMAGE_SIZE,\n","    width=IMAGE_SIZE,\n","    generator=torch.Generator('cuda').manual_seed(SEED),\n","    ).images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaKnqiyUfG1h"},"outputs":[],"source":["from PIL import Image\n","\n","def image_grid(imgs, rows, cols):\n","    assert len(imgs) == rows*cols\n","\n","    w, h = imgs[0].size\n","    grid = Image.new('RGB', size=(cols*w, rows*h))\n","    grid_w, grid_h = grid.size\n","\n","    for i, img in enumerate(imgs):\n","        grid.paste(img, box=(i%cols*w, i//cols*h))\n","    return grid\n","\n","grid = image_grid(images, rows=2, cols=2)\n","grid"]},{"cell_type":"markdown","metadata":{"id":"zW2ni9QefG1i"},"source":["Now, it's time to generate images from your own text and hyperparameters.\n","\n","help yourself to use any values and text and submit the most creative and best results!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSIkewWxfG1j"},"outputs":[],"source":["NUM_IMAGES = 4\n","\n","prompt = # Target Text\n","GUIDANCE_SCALE = # hyperparameter to control the trade-off between generation diversity and quality\n","NUM_DENOISING_STEPS = # hyperparameter to control the trade-off between the speed and quality\n","SEED = # random seed setting for stochasticity in denoising step\n","\n","\n","images = pipe(\n","    prompt,\n","    num_images_per_prompt=NUM_IMAGES,\n","    guidance_scale=GUIDANCE_SCALE,\n","    num_inference_steps=NUM_DENOISING_STEPS,\n","    height=IMAGE_SIZE,\n","    width=IMAGE_SIZE,\n","    generator=torch.Generator('cuda').manual_seed(SEED),\n","    ).images\n","\n","grid = image_grid(images, rows=2, cols=2)\n","grid\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cw8f8YfmfG1k"},"outputs":[],"source":["import os\n","\n","out_dir = './stable_diffusion_result'\n","os.makedirs(out_dir, exist_ok=True)\n","\n","for i, x in enumerate(images):\n","    x.save(os.path.join(out_dir, '%d.png'%(i+1)))"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb","timestamp":1669946478530}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.12 ('dl_2022')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"vscode":{"interpreter":{"hash":"07d22452b20408ffb63ff7af541ea70f1482b1754eeab403cb7a35610db14220"}}},"nbformat":4,"nbformat_minor":0}